{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training  Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=[]\n",
    "train_samples=[]\n",
    "\n",
    "for i in range(50):\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "for i in range(1000):\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)\n",
    "train_labels, train_samples = shuffle(train_labels, train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1890 samples, validate on 210 samples\n",
      "Epoch 1/30\n",
      "1890/1890 - 1s - loss: 0.6572 - acc: 0.5370 - val_loss: 0.6502 - val_acc: 0.5476\n",
      "Epoch 2/30\n",
      "1890/1890 - 0s - loss: 0.6296 - acc: 0.6317 - val_loss: 0.6238 - val_acc: 0.6238\n",
      "Epoch 3/30\n",
      "1890/1890 - 0s - loss: 0.6004 - acc: 0.6820 - val_loss: 0.5992 - val_acc: 0.6857\n",
      "Epoch 4/30\n",
      "1890/1890 - 0s - loss: 0.5729 - acc: 0.7333 - val_loss: 0.5750 - val_acc: 0.7143\n",
      "Epoch 5/30\n",
      "1890/1890 - 0s - loss: 0.5455 - acc: 0.7646 - val_loss: 0.5499 - val_acc: 0.7524\n",
      "Epoch 6/30\n",
      "1890/1890 - 0s - loss: 0.5178 - acc: 0.7958 - val_loss: 0.5250 - val_acc: 0.7810\n",
      "Epoch 7/30\n",
      "1890/1890 - 0s - loss: 0.4904 - acc: 0.8275 - val_loss: 0.5003 - val_acc: 0.8048\n",
      "Epoch 8/30\n",
      "1890/1890 - 0s - loss: 0.4635 - acc: 0.8529 - val_loss: 0.4771 - val_acc: 0.8238\n",
      "Epoch 9/30\n",
      "1890/1890 - 0s - loss: 0.4378 - acc: 0.8598 - val_loss: 0.4545 - val_acc: 0.8571\n",
      "Epoch 10/30\n",
      "1890/1890 - 0s - loss: 0.4138 - acc: 0.8778 - val_loss: 0.4337 - val_acc: 0.8571\n",
      "Epoch 11/30\n",
      "1890/1890 - 0s - loss: 0.3920 - acc: 0.8931 - val_loss: 0.4159 - val_acc: 0.8714\n",
      "Epoch 12/30\n",
      "1890/1890 - 0s - loss: 0.3724 - acc: 0.8995 - val_loss: 0.3999 - val_acc: 0.8714\n",
      "Epoch 13/30\n",
      "1890/1890 - 0s - loss: 0.3553 - acc: 0.9116 - val_loss: 0.3863 - val_acc: 0.8714\n",
      "Epoch 14/30\n",
      "1890/1890 - 0s - loss: 0.3400 - acc: 0.9127 - val_loss: 0.3746 - val_acc: 0.8810\n",
      "Epoch 15/30\n",
      "1890/1890 - 0s - loss: 0.3272 - acc: 0.9175 - val_loss: 0.3648 - val_acc: 0.8810\n",
      "Epoch 16/30\n",
      "1890/1890 - 0s - loss: 0.3161 - acc: 0.9201 - val_loss: 0.3567 - val_acc: 0.8810\n",
      "Epoch 17/30\n",
      "1890/1890 - 0s - loss: 0.3067 - acc: 0.9233 - val_loss: 0.3501 - val_acc: 0.8810\n",
      "Epoch 18/30\n",
      "1890/1890 - 0s - loss: 0.2986 - acc: 0.9265 - val_loss: 0.3446 - val_acc: 0.8810\n",
      "Epoch 19/30\n",
      "1890/1890 - 0s - loss: 0.2917 - acc: 0.9312 - val_loss: 0.3401 - val_acc: 0.8810\n",
      "Epoch 20/30\n",
      "1890/1890 - 0s - loss: 0.2860 - acc: 0.9312 - val_loss: 0.3363 - val_acc: 0.8810\n",
      "Epoch 21/30\n",
      "1890/1890 - 0s - loss: 0.2809 - acc: 0.9312 - val_loss: 0.3332 - val_acc: 0.8810\n",
      "Epoch 22/30\n",
      "1890/1890 - 0s - loss: 0.2766 - acc: 0.9317 - val_loss: 0.3307 - val_acc: 0.8952\n",
      "Epoch 23/30\n",
      "1890/1890 - 0s - loss: 0.2731 - acc: 0.9360 - val_loss: 0.3284 - val_acc: 0.8810\n",
      "Epoch 24/30\n",
      "1890/1890 - 0s - loss: 0.2698 - acc: 0.9349 - val_loss: 0.3266 - val_acc: 0.8952\n",
      "Epoch 25/30\n",
      "1890/1890 - 0s - loss: 0.2669 - acc: 0.9397 - val_loss: 0.3250 - val_acc: 0.8952\n",
      "Epoch 26/30\n",
      "1890/1890 - 0s - loss: 0.2644 - acc: 0.9397 - val_loss: 0.3236 - val_acc: 0.8952\n",
      "Epoch 27/30\n",
      "1890/1890 - 0s - loss: 0.2622 - acc: 0.9397 - val_loss: 0.3225 - val_acc: 0.8952\n",
      "Epoch 28/30\n",
      "1890/1890 - 0s - loss: 0.2601 - acc: 0.9397 - val_loss: 0.3214 - val_acc: 0.8952\n",
      "Epoch 29/30\n",
      "1890/1890 - 0s - loss: 0.2584 - acc: 0.9397 - val_loss: 0.3205 - val_acc: 0.8952\n",
      "Epoch 30/30\n",
      "1890/1890 - 0s - loss: 0.2567 - acc: 0.9397 - val_loss: 0.3196 - val_acc: 0.8952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f61ce1c4160>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'shuffle' ensures shuffling of training data; but if we take validation data as seen here, \n",
    "#  we are taking away 'validation data' first, then shuffling our data\n",
    "\n",
    "model.fit( \n",
    "           x=scaled_train_samples, \n",
    "           y=train_labels, \n",
    "           validation_split=0.1, \n",
    "           batch_size=10, \n",
    "           epochs=30, \n",
    "           shuffle=True, \n",
    "           verbose=2\n",
    "         )\n",
    "\n",
    "# verbose {0,1,2} defines how much information you want during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test  Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels=[]\n",
    "test_samples=[]\n",
    "\n",
    "for i in range(10):\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "    random_younger = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "for i in range(200):\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "    random_younger = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(test_labels)\n",
    "test_samples = np.array(test_samples)\n",
    "test_labels, test_samples = shuffle(test_labels, test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test_samples = scaler.fit_transform(test_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 76us/sample\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x=scaled_test_samples, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.94962573 0.05037433]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.95050675 0.04949329]\n",
      "[0.9458847  0.05411524]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9484373 0.0515627]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9525561  0.04744396]\n",
      "[0.9516321  0.04836798]\n",
      "[0.9516321  0.04836798]\n",
      "[0.95207745 0.04792254]\n",
      "[0.620687 0.379313]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.620687 0.379313]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9526653  0.04733468]\n",
      "[0.58658177 0.41341823]\n",
      "[0.9511826  0.04881733]\n",
      "[0.95188206 0.04811795]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9472225  0.05277754]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.87198216 0.12801784]\n",
      "[0.9182229  0.08177707]\n",
      "[0.9525561  0.04744396]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.95148265 0.04851733]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9529567  0.04704334]\n",
      "[0.95188206 0.04811795]\n",
      "[0.95237225 0.04762776]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9507293  0.04927066]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.94962573 0.05037433]\n",
      "[0.7151044  0.28489554]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.51615065 0.48384944]\n",
      "[0.7695075  0.23049244]\n",
      "[0.8552005 0.1447995]\n",
      "[0.48051286 0.5194871 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.95148265 0.04851733]\n",
      "[0.74324805 0.25675198]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9472225  0.05277754]\n",
      "[0.9182229  0.08177707]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.953056   0.04694409]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9484373 0.0515627]\n",
      "[0.6851825 0.3148175]\n",
      "[0.94962573 0.05037433]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9005788  0.09942114]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.95207745 0.04792254]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9529567  0.04704334]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.8366312  0.16336885]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9526653  0.04733468]\n",
      "[0.9526653  0.04733468]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.48051286 0.5194871 ]\n",
      "[0.9005788  0.09942114]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.87198216 0.12801784]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.6851825 0.3148175]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.95148265 0.04851733]\n",
      "[0.9507293  0.04927066]\n",
      "[0.65364033 0.34635973]\n",
      "[0.9526653  0.04733468]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.95133287 0.04866711]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9182229  0.08177707]\n",
      "[0.8870758  0.11292426]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.6851825 0.3148175]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.87198216 0.12801784]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.951032 0.048968]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.952519   0.04748101]\n",
      "[0.9484373 0.0515627]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.7151044  0.28489554]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.8870758  0.11292426]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9005788  0.09942114]\n",
      "[0.8552005 0.1447995]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.95133287 0.04866711]\n",
      "[0.9526653  0.04733468]\n",
      "[0.951032 0.048968]\n",
      "[0.94962573 0.05037433]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.951199   0.04880102]\n",
      "[0.551625   0.44837496]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.51615065 0.48384944]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9511826  0.04881733]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9005788  0.09942114]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9529567  0.04704334]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.58658177 0.41341823]\n",
      "[0.9528112  0.04718881]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.51615065 0.48384944]\n",
      "[0.95310163 0.04689829]\n",
      "[0.952519   0.04748101]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9484373 0.0515627]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.951781   0.04821907]\n",
      "[0.7695075  0.23049244]\n",
      "[0.9528112  0.04718881]\n",
      "[0.951032 0.048968]\n",
      "[0.95133287 0.04866711]\n",
      "[0.9528112  0.04718881]\n",
      "[0.9529567  0.04704334]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9381113  0.06188872]\n",
      "[0.95188206 0.04811795]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.951781   0.04821907]\n",
      "[0.8366312  0.16336885]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.95192945 0.04807058]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.94962573 0.05037433]\n",
      "[0.95188206 0.04811795]\n",
      "[0.48051286 0.5194871 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9525561  0.04744396]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9516321  0.04836798]\n",
      "[0.952519   0.04748101]\n",
      "[0.44507214 0.5549279 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9484373 0.0515627]\n",
      "[0.74324805 0.25675198]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.87198216 0.12801784]\n",
      "[0.94962573 0.05037433]\n",
      "[0.58658177 0.41341823]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9507293  0.04927066]\n",
      "[0.8552005 0.1447995]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.7938264  0.20617366]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9472225  0.05277754]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.6851825 0.3148175]\n",
      "[0.93378574 0.06621426]\n",
      "[0.951199   0.04880102]\n",
      "[0.8366312  0.16336885]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.95192945 0.04807058]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9511826  0.04881733]\n",
      "[0.9525561  0.04744396]\n",
      "[0.9522251  0.04777493]\n",
      "[0.6851825 0.3148175]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9289309 0.0710691]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.94156164 0.05843842]\n",
      "[0.93378574 0.06621426]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.93378574 0.06621426]\n",
      "[0.9182229  0.08177707]\n",
      "[0.9381113  0.06188872]\n",
      "[0.51615065 0.48384944]\n",
      "[0.9289309 0.0710691]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.952519   0.04748101]\n",
      "[0.620687 0.379313]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9511826  0.04881733]\n",
      "[0.94156164 0.05843842]\n",
      "[0.74324805 0.25675198]\n",
      "[0.9289309 0.0710691]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.952519   0.04748101]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.94405633 0.0559437 ]\n",
      "[0.95148265 0.04851733]\n",
      "[0.74324805 0.25675198]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.620687 0.379313]\n",
      "[0.44507214 0.5549279 ]\n",
      "[0.8552005 0.1447995]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.8161922  0.18380778]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.95207745 0.04792254]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.7151044  0.28489554]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.8161922  0.18380778]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9381113  0.06188872]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.94405633 0.0559437 ]\n",
      "[0.8366312  0.16336885]\n",
      "[0.51615065 0.48384944]\n",
      "[0.952519   0.04748101]\n",
      "[0.9472225  0.05277754]\n",
      "[0.44507214 0.5549279 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9381113  0.06188872]\n",
      "[0.48051286 0.5194871 ]\n",
      "[0.9528112  0.04718881]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9528112  0.04718881]\n",
      "[0.9522251  0.04777493]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9484373 0.0515627]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9526653  0.04733468]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.620687 0.379313]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.951781   0.04821907]\n",
      "[0.95192945 0.04807058]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.951199   0.04880102]\n",
      "[0.9381113  0.06188872]\n",
      "[0.9511826  0.04881733]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9525561  0.04744396]\n",
      "[0.953056   0.04694409]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.951199   0.04880102]\n",
      "[0.74324805 0.25675198]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9484373 0.0515627]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.7151044  0.28489554]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.951781   0.04821907]\n",
      "[0.9529567  0.04704334]\n",
      "[0.7695075  0.23049244]\n",
      "[0.95188206 0.04811795]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.6851825 0.3148175]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9528112  0.04718881]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.951199   0.04880102]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.93378574 0.06621426]\n",
      "[0.93378574 0.06621426]\n",
      "[0.9484373 0.0515627]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.94405633 0.0559437 ]\n",
      "[0.9522251  0.04777493]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.48051286 0.5194871 ]\n",
      "[0.58658177 0.41341823]\n",
      "[0.9381113  0.06188872]\n",
      "[0.95192945 0.04807058]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.7151044  0.28489554]\n",
      "[0.95310163 0.04689829]\n",
      "[0.65364033 0.34635973]\n",
      "[0.94405633 0.0559437 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.551625   0.44837496]\n",
      "[0.58658177 0.41341823]\n",
      "[0.94405633 0.0559437 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9511826  0.04881733]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.95188206 0.04811795]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.95148265 0.04851733]\n",
      "[0.6851825 0.3148175]\n",
      "[0.8552005 0.1447995]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9529567  0.04704334]\n",
      "[0.95050675 0.04949329]\n",
      "[0.9237492  0.07625081]\n",
      "[0.951199   0.04880102]\n",
      "[0.8366312  0.16336885]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.74324805 0.25675198]\n",
      "[0.8870758  0.11292426]\n",
      "[0.95237225 0.04762776]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9182229  0.08177707]\n",
      "[0.65364033 0.34635973]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.951781   0.04821907]\n",
      "[0.7151044  0.28489554]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.9526653  0.04733468]\n",
      "[0.9005788  0.09942114]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.01518513 0.9848149 ]\n",
      "[0.953056   0.04694409]\n"
     ]
    }
   ],
   "source": [
    "for i in predictions: \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = np.argmax(predictions, axis=-1)\n",
    "# better visualisation of 'predictions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in rounded_predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a CONFUSION  MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_labels, y_pred=rounded_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for creating 'CONFUSION MATRIX' by sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, \n",
    "                          title='Confusion Matrix', \n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Confusion matrix w/o normalization\")\n",
    "        \n",
    "    print(cm)\n",
    "    \n",
    "    thres = cm.max()/2\n",
    "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i,j], horizontalalignment=\"center\", color=\"white\" if cm[i, j]>thres else \"black\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('TRUE LABEL')\n",
    "    plt.xlabel('PREDICTED LABEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix w/o normalization\n",
      "[[194  16]\n",
      " [  8 202]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels = ['no_side_effects', 'had_side_effects']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### total 420 predictions (194+16+8+202)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE AND LOAD the MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "#checks first to see if file already exists; if not, model is saved to disk\n",
    "\n",
    "if os.path.isfile('medical_trial_model.h5') is False:\n",
    "    model.save('medical_trial_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This save function saves:\n",
    "    \n",
    "    * architecture of model, allowing to re-create vmodel\n",
    "    * weights of model\n",
    "    * training configuration (loss, optimizer)\n",
    "    * state of optimizer(allowing to resume wher you left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0628 17:16:23.353070 140060496435008 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0628 17:16:23.355358 140060496435008 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "new_model = load_model('medical_trial_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.optimizer_v2.adam.Adam at 0x7f616b598780>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_model.get_weights()\n",
    "new_model.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. model.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you only want to save the architecture of the model and not its weights or training configuration, use this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as JSON\n",
    "json_string = model.to_json()\n",
    "\n",
    "#save as YAML\n",
    "# yaml_string = model.to_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_1\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_3\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_4\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_5\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.2.4-tf\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###                     model reconstruction from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "model_architecture = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_architecture.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. model.save_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "if os.path.isfile('my_model_weights.h5') is False:\n",
    "    model.save_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.6041174 , -0.08602118,  0.5428787 , -0.00269926,  0.33199432,\n",
       "          0.366466  , -0.2690934 ,  0.18575789, -0.53320456,  0.20138848,\n",
       "          0.6621503 , -0.2511335 , -0.45871472,  0.1460615 , -0.39808244,\n",
       "          0.45476446]], dtype=float32),\n",
       " array([-0.12213531,  0.        , -0.13487554,  0.        , -0.10521121,\n",
       "        -0.11140323,  0.        , -0.06957303,  0.        , -0.07466364,\n",
       "        -0.12662992,  0.        ,  0.        ,  0.2265446 ,  0.        ,\n",
       "        -0.12914164], dtype=float32),\n",
       " array([[-4.61414382e-02, -1.27808750e-02,  1.57052159e-01,\n",
       "          1.23501301e-01, -2.56646544e-01,  3.81814241e-01,\n",
       "         -2.62800604e-01, -2.24511921e-02, -7.50876293e-02,\n",
       "         -2.44666114e-01, -1.08430728e-01, -9.21803489e-02,\n",
       "          9.86567661e-02,  2.31543779e-01, -1.79205582e-01,\n",
       "         -1.64363652e-01,  1.89202309e-01,  1.85583085e-01,\n",
       "         -3.23811144e-01, -2.53889233e-01, -1.41784891e-01,\n",
       "          9.44233313e-02,  7.06501231e-02, -3.21416676e-01,\n",
       "         -2.28174612e-01, -2.55759209e-01,  1.29207075e-02,\n",
       "          4.11048949e-01, -1.61279231e-01,  2.03012489e-02,\n",
       "          3.41485053e-01, -2.06828713e-01],\n",
       "        [ 1.71231598e-01, -1.35092020e-01, -3.02055091e-01,\n",
       "         -3.62234414e-02, -1.13015085e-01, -2.35217512e-01,\n",
       "          2.05729634e-01,  3.60132158e-02,  2.85685062e-04,\n",
       "         -8.05434585e-03, -1.34049818e-01,  2.28479177e-01,\n",
       "          1.16717219e-02,  1.72870010e-01, -8.43939185e-02,\n",
       "         -3.34762633e-01,  8.44718218e-02, -7.54648447e-02,\n",
       "         -1.63486108e-01,  3.46819133e-01, -4.83742058e-02,\n",
       "          1.77037090e-01, -1.84881866e-01, -2.87922144e-01,\n",
       "          1.20463878e-01, -4.05988693e-02, -3.12836230e-01,\n",
       "         -2.01536447e-01, -1.11032754e-01,  2.44244426e-01,\n",
       "          8.95600319e-02,  1.61732346e-01],\n",
       "        [ 5.09645700e-01, -3.66287231e-02, -8.95792395e-02,\n",
       "         -3.85715187e-01,  2.35963494e-01,  3.03012758e-01,\n",
       "          1.07664287e-01, -1.17327303e-01,  3.15665871e-01,\n",
       "         -2.26198241e-01,  1.61818806e-02,  3.34241567e-03,\n",
       "          2.16470897e-01, -2.96431214e-01, -2.81247675e-01,\n",
       "          3.56381804e-01,  3.44463848e-02, -2.63476372e-01,\n",
       "         -1.55569687e-01, -5.14378548e-02,  4.73975718e-01,\n",
       "          4.95013833e-01, -1.70490116e-01,  1.78283185e-01,\n",
       "         -2.25838274e-01, -9.33761597e-02, -3.25446397e-01,\n",
       "          2.33096749e-01,  2.91551113e-01, -3.63426775e-01,\n",
       "         -1.73528135e-01,  6.27636611e-02],\n",
       "        [-3.42102498e-01,  1.36727661e-01, -3.50419521e-01,\n",
       "          1.50577039e-01,  2.24031240e-01,  9.85229909e-02,\n",
       "         -9.38024521e-02,  3.04351658e-01,  3.53046358e-02,\n",
       "         -2.48228163e-01,  1.50261968e-01, -2.06663609e-01,\n",
       "          1.32730275e-01, -2.70832956e-01, -1.72994599e-01,\n",
       "          4.75235283e-02,  2.52987951e-01, -1.50405079e-01,\n",
       "          2.64191180e-01,  2.08986104e-02,  1.74975097e-02,\n",
       "         -1.86245069e-01,  2.47546583e-01,  2.51895338e-01,\n",
       "          1.95025593e-01,  1.08616799e-01,  5.82171082e-02,\n",
       "         -2.98972458e-01, -2.56890863e-01,  1.14743859e-01,\n",
       "         -2.26430818e-01, -3.12326521e-01],\n",
       "        [ 5.53448200e-01, -1.01682544e-01,  1.93256326e-02,\n",
       "          3.31470706e-02, -7.20910132e-02,  5.01603365e-01,\n",
       "         -2.05071807e-01, -1.07549146e-01,  2.68072397e-01,\n",
       "          3.37055139e-02, -4.43706304e-01,  1.69028297e-01,\n",
       "          4.68359590e-01, -1.89114347e-01,  7.25747198e-02,\n",
       "          5.01897514e-01,  5.02792656e-01,  3.70282829e-02,\n",
       "          1.55762956e-01, -1.68874070e-01,  5.29119134e-01,\n",
       "          1.28604665e-01, -3.02505076e-01, -2.97472447e-01,\n",
       "         -2.24434227e-01, -4.77472246e-02, -6.70457780e-02,\n",
       "         -6.72108904e-02,  5.33268392e-01, -3.76813710e-02,\n",
       "          4.89590526e-01, -5.40818870e-01],\n",
       "        [ 3.05599868e-01, -2.31486261e-01,  4.49494958e-01,\n",
       "         -5.16010582e-01, -1.08557209e-01, -6.26569539e-02,\n",
       "         -3.06981951e-01, -2.99286276e-01, -1.59506261e-01,\n",
       "         -2.20237836e-01, -2.71835953e-01, -2.77194709e-01,\n",
       "          1.33260399e-01, -8.44722390e-02,  3.11906725e-01,\n",
       "          5.45660377e-01,  2.69185364e-01, -2.65290976e-01,\n",
       "         -5.12692094e-01,  2.71787554e-01,  4.66150820e-01,\n",
       "         -5.09562492e-02,  4.35845219e-02, -4.81367707e-02,\n",
       "         -5.14563881e-02, -3.01902503e-01,  1.97742879e-02,\n",
       "          2.26956666e-01,  2.02175304e-01, -2.87429869e-01,\n",
       "          4.28865850e-01, -1.72039911e-01],\n",
       "        [-1.61195010e-01,  2.08975077e-02,  2.23048627e-02,\n",
       "          3.38702589e-01, -1.06680393e-02, -5.11252284e-02,\n",
       "         -1.66168332e-01,  1.33427829e-01,  1.71908885e-01,\n",
       "         -1.99253350e-01, -1.85610667e-01,  1.45045161e-01,\n",
       "         -3.10643584e-01, -3.08381826e-01, -3.04268390e-01,\n",
       "          1.33510351e-01,  2.33086079e-01,  3.33468318e-02,\n",
       "         -3.56957614e-02,  1.38766766e-02,  3.19398940e-02,\n",
       "         -3.20338547e-01, -1.93046138e-01, -2.20145121e-01,\n",
       "          2.55747169e-01, -1.71277702e-01,  3.13854814e-02,\n",
       "         -1.27297893e-01, -1.38918281e-01, -1.39219210e-01,\n",
       "         -1.19645879e-01,  2.49584287e-01],\n",
       "        [ 6.52182102e-02,  1.03229523e-01,  6.20422550e-02,\n",
       "         -5.45385718e-01,  2.24942312e-01,  6.05606019e-01,\n",
       "          1.52409673e-02, -1.34434372e-01,  9.97942016e-02,\n",
       "         -4.61169600e-01, -1.67774186e-01, -3.07372659e-01,\n",
       "          6.07292712e-01, -2.42101356e-01, -7.94426873e-02,\n",
       "          6.13801479e-02,  3.25822353e-01,  6.49369061e-02,\n",
       "          2.24857349e-02,  1.64027125e-01,  4.26240683e-01,\n",
       "          1.61921158e-01, -4.54732150e-01, -9.52512026e-02,\n",
       "         -1.52376086e-01,  1.72216147e-01, -5.29198349e-02,\n",
       "          4.14206982e-01, -1.90987606e-02, -6.64068818e-01,\n",
       "          4.54454243e-01, -3.91280860e-01],\n",
       "        [-4.57251072e-02,  3.13089877e-01,  1.55105621e-01,\n",
       "         -2.21196935e-01, -1.45449862e-01,  2.84101039e-01,\n",
       "         -2.72434711e-01,  3.43540281e-01,  1.18690401e-01,\n",
       "         -1.53835490e-01, -2.47893512e-01,  2.25517422e-01,\n",
       "          1.90028340e-01,  1.87602609e-01, -3.39045674e-01,\n",
       "         -1.99475557e-01,  8.58120024e-02,  1.77382529e-02,\n",
       "          6.62254393e-02,  1.03878081e-01,  1.22967362e-03,\n",
       "         -1.94734707e-01, -3.47755581e-01,  5.51434159e-02,\n",
       "         -1.77371547e-01, -9.69690979e-02,  3.49656731e-01,\n",
       "          2.29655296e-01, -8.03559124e-02, -2.61630774e-01,\n",
       "         -1.33768871e-01,  1.00268453e-01],\n",
       "        [ 2.39573538e-01, -2.83164203e-01,  5.28354526e-01,\n",
       "         -4.66661960e-01, -2.87221581e-01,  5.96734464e-01,\n",
       "          3.62160802e-03,  2.09622473e-01, -3.25059921e-01,\n",
       "         -4.10122842e-01, -3.60796243e-01, -4.27748144e-01,\n",
       "          3.76571089e-01,  1.76883072e-01,  1.87843591e-01,\n",
       "          5.01825333e-01,  4.35821980e-01,  1.13687754e-01,\n",
       "         -1.87088713e-01,  1.42622054e-01,  6.03315309e-02,\n",
       "          1.22128524e-01, -3.78120989e-01, -1.88139379e-02,\n",
       "         -2.30900571e-01, -1.93550795e-01,  2.42379516e-01,\n",
       "          5.87134004e-01,  4.67935920e-01, -3.75273556e-01,\n",
       "          2.83066362e-01, -2.23972172e-01],\n",
       "        [ 2.40111247e-01, -2.42064938e-01,  4.54719901e-01,\n",
       "         -1.28999144e-01, -2.06967101e-01,  2.41285056e-01,\n",
       "         -7.17781186e-02, -1.59909695e-01, -2.78286576e-01,\n",
       "          2.03296378e-01, -4.04428571e-01,  9.66017246e-02,\n",
       "          3.72140795e-01, -3.54739517e-01, -3.36541831e-01,\n",
       "          2.90109038e-01,  2.04521775e-01, -1.35542244e-01,\n",
       "         -2.91045517e-01,  2.21483439e-01,  4.89231348e-01,\n",
       "          1.48809046e-01, -3.41849536e-01,  3.40640515e-01,\n",
       "         -1.65990114e-01, -1.29982367e-01, -1.71860516e-01,\n",
       "          1.53803870e-01,  5.11786401e-01, -8.58084336e-02,\n",
       "          1.31248504e-01, -3.08121517e-02],\n",
       "        [ 2.09437996e-01, -1.65182009e-01,  1.65741295e-01,\n",
       "          1.37267381e-01, -1.13925114e-01, -1.43690318e-01,\n",
       "         -1.38394147e-01,  2.42082387e-01, -2.60070145e-01,\n",
       "          9.35199857e-02,  1.46310836e-01, -1.92635372e-01,\n",
       "         -2.20315993e-01, -1.93300366e-01, -3.12578291e-01,\n",
       "          3.48566979e-01, -5.40466011e-02,  2.79809326e-01,\n",
       "         -2.17603758e-01,  3.42628688e-01,  2.26121873e-01,\n",
       "         -2.32299000e-01, -3.34499121e-01,  2.45846361e-01,\n",
       "         -4.93874252e-02, -1.68230996e-01, -3.28915596e-01,\n",
       "          3.24256033e-01, -3.37036610e-01, -2.73630917e-01,\n",
       "          3.43759328e-01, -8.23345780e-03],\n",
       "        [ 2.04292625e-01, -3.36584210e-01,  3.42657357e-01,\n",
       "          5.47283888e-03,  1.99331731e-01,  9.25911367e-02,\n",
       "          1.97643429e-01,  2.21113771e-01, -1.63244948e-01,\n",
       "         -1.97474003e-01,  4.60678637e-02,  3.33495706e-01,\n",
       "         -8.89003575e-02, -7.60466456e-02,  1.55497581e-01,\n",
       "          3.14071327e-01, -3.33130717e-01, -2.97843754e-01,\n",
       "          1.84216172e-01, -6.32301271e-02, -1.49835244e-01,\n",
       "         -1.96517855e-01,  2.25197107e-01, -2.99438089e-01,\n",
       "         -1.20919809e-01,  6.11386299e-02, -1.64362922e-01,\n",
       "         -3.44215035e-02,  3.49043310e-02,  2.92700082e-01,\n",
       "         -1.44284666e-02,  1.55934662e-01],\n",
       "        [-7.61583298e-02, -1.05751336e-01, -1.04852594e-01,\n",
       "          2.31123060e-01,  8.41455068e-03,  2.78388262e-01,\n",
       "         -2.07017481e-01, -3.37045550e-01, -3.12933534e-01,\n",
       "          7.20941052e-02,  2.16129959e-01,  3.00283313e-01,\n",
       "          3.09229404e-01,  1.04238845e-01,  8.75307024e-02,\n",
       "          2.92667180e-01,  3.05272967e-01, -1.82696730e-01,\n",
       "          4.34634089e-01, -2.63814986e-01, -1.28471464e-01,\n",
       "          1.26177697e-02,  2.99432129e-01, -9.76710916e-02,\n",
       "          2.18847439e-01,  1.56898275e-01, -1.67129621e-01,\n",
       "          2.28598386e-01, -2.19097927e-01, -1.28645778e-01,\n",
       "         -1.80018600e-02,  7.86655247e-02],\n",
       "        [ 2.09432989e-01, -1.86358094e-02,  8.31145942e-02,\n",
       "         -2.79036760e-01, -3.10225248e-01, -1.53738558e-01,\n",
       "         -8.06470513e-02,  3.46433014e-01,  6.38564229e-02,\n",
       "          3.48200172e-01,  2.01380700e-01, -3.20649147e-02,\n",
       "          2.19411701e-01,  1.57616466e-01, -1.75995126e-01,\n",
       "         -3.10008943e-01, -3.51579636e-01, -3.22597206e-01,\n",
       "         -2.77617872e-02,  2.14170665e-01, -2.70119995e-01,\n",
       "         -1.80745661e-01,  3.04915518e-01, -7.42597878e-02,\n",
       "          1.35027468e-02, -1.84621483e-01,  3.17410380e-01,\n",
       "         -2.98331082e-01, -1.76572114e-01,  7.35057890e-02,\n",
       "          2.25316286e-02, -7.54321516e-02],\n",
       "        [ 2.35190049e-01,  1.16107643e-01,  2.21024558e-01,\n",
       "         -6.23772405e-02, -3.41132283e-02,  5.31865180e-01,\n",
       "         -3.27337027e-01,  3.25663716e-01,  2.11258024e-01,\n",
       "          7.01967925e-02, -4.33980674e-03, -1.95936516e-01,\n",
       "          5.00853300e-01, -8.20595026e-02,  2.02390164e-01,\n",
       "          5.08015633e-01,  1.14662558e-01, -1.16311640e-01,\n",
       "         -1.73814502e-02, -1.93265721e-01, -1.30645990e-01,\n",
       "          2.58893162e-01, -4.70017791e-01, -8.34218562e-02,\n",
       "         -2.46546626e-01,  1.02162033e-01,  1.70570016e-02,\n",
       "          3.19754243e-01,  3.45396459e-01,  1.66098714e-01,\n",
       "          1.35236308e-01, -2.78012574e-01]], dtype=float32),\n",
       " array([-0.07156018,  0.        , -0.0635703 ,  0.1964136 , -0.00455369,\n",
       "        -0.13202833,  0.        ,  0.        , -0.00073558,  0.20657168,\n",
       "         0.2619361 ,  0.18585655, -0.12048786, -0.0270564 , -0.0224283 ,\n",
       "        -0.11382532, -0.12521526, -0.00052085,  0.23313637,  0.        ,\n",
       "        -0.06401511, -0.07690407,  0.254346  ,  0.        ,  0.25259888,\n",
       "        -0.03987646,  0.        , -0.12450605, -0.04791592,  0.24210149,\n",
       "        -0.0676984 ,  0.23719047], dtype=float32),\n",
       " array([[-0.1506159 ,  0.41237146],\n",
       "        [ 0.17160282, -0.41906664],\n",
       "        [-0.5992671 ,  0.59455085],\n",
       "        [ 0.6756449 , -0.69855344],\n",
       "        [-0.01507995,  0.16415544],\n",
       "        [-0.13398169,  0.38855827],\n",
       "        [ 0.10967675,  0.3526382 ],\n",
       "        [ 0.10854378,  0.02028346],\n",
       "        [-0.29726613,  0.21528693],\n",
       "        [ 0.00330399, -0.46773672],\n",
       "        [ 0.4020807 , -0.6588561 ],\n",
       "        [ 0.322731  , -0.3914324 ],\n",
       "        [-0.4420927 ,  0.4654204 ],\n",
       "        [-0.08405901,  0.21475974],\n",
       "        [-0.1011176 ,  0.0208059 ],\n",
       "        [-0.55018497,  0.01810652],\n",
       "        [ 0.03947505,  0.5366047 ],\n",
       "        [ 0.30533576,  0.32453525],\n",
       "        [ 0.5706897 , -0.725792  ],\n",
       "        [ 0.01568061, -0.09700224],\n",
       "        [-0.56310797,  0.14276378],\n",
       "        [-0.2761896 ,  0.6579118 ],\n",
       "        [ 0.70104235, -0.5708331 ],\n",
       "        [-0.1872223 , -0.33867347],\n",
       "        [ 0.6214475 , -0.43278798],\n",
       "        [ 0.17571442,  0.2016138 ],\n",
       "        [-0.21484639, -0.23621003],\n",
       "        [-0.3344833 ,  0.23800552],\n",
       "        [-0.44850278,  0.5857245 ],\n",
       "        [ 0.5086534 , -0.47808817],\n",
       "        [-0.19902132,  0.6584543 ],\n",
       "        [ 0.731351  , -0.36721128]], dtype=float32),\n",
       " array([ 0.1766733 , -0.17667334], dtype=float32)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.get_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
